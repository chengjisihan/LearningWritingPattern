{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import numpy as np\n",
    "import jieba\n",
    "import nltk\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从个人数据库中读取表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine = create_engine('mysql://root:650921abc@localhost:3306/Stock_Linkage?charset=utf8') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_sql('Stock_Linkage_Content', engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = []\n",
    "for index, row in df1.iterrows():\n",
    "    news.append(row['Content'])\n",
    "#s = unicode(news, 'gb2312')\n",
    "#for i in np.arange(len(news)):\n",
    "#    print(news[i].encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(news[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in np.arange(len(news)):\n",
    "#    print(news[i].encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用结巴分词对文本进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('companys.txt','r') as f:\n",
    "    for line in f:\n",
    "        jieba.suggest_freq(line, tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jieba.set_dictionary('dict.txt.big.txt')\n",
    "seg_list = []\n",
    "for i in np.arange(len(news)):\n",
    "    seg_list.append(jieba.cut(news[i].encode('utf8')))\n",
    "print(\"Full Mode: \" + \"/ \".join(seg_list[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模板 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(repr('（'))\n",
    "#print(repr('）'))\n",
    "print(repr(u'增'))\n",
    "print(repr(u'升'))\n",
    "print(repr(u'跌'))\n",
    "print(repr(u'收市上升'))\n",
    "print(repr(u'收市跌'))\n",
    "print(repr(u'收市下跌'))\n",
    "print(repr(u'跌落'))\n",
    "verb_list = [repr(u'收市'),repr(u'增'), repr(u'升'), repr(u'跌'), repr(u'上升'), repr(u'跌落')]\n",
    "#print(repr(news[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(r\"\\(-?[0-9]*\\.?[0-9]+\\%\\)\")\n",
    "pattern2 = re.compile(ur\".*[\\u4E00-\\u9FA5]+.*\")\n",
    "pattern3 = re.compile(ur\"\")\n",
    "pattern4 = re.compile(ur\"\\u6536\\u5e02\\u4e0a?\\u4e0b?[\\u5347\\u8dcc]+\\u843d?\\s?-?[0-9]*\\.?[0-9]+\\s?\\%|\\u4e0a?\\u4e0b?[\\u5347\\u8dcc]+\\u843d?\\s?-?[0-9]*\\.?[0-9]+\\s?\\%\")\n",
    "pattern5 = re.compile(ur\"\\u6536\\u5e02\\u4e0a?\\u4e0b?[\\u5347\\u8dcc]+\\u843d?\\s?-?[0-9]*\\.?[0-9]+\\s?\\%\")\n",
    "match = pattern4.findall(news[6])\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取第一种格式的涨跌幅度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_rate = []\n",
    "for i in np.arange(len(news)):\n",
    "    match = pattern1.findall(news[i])\n",
    "    ex_rate.append(match)\n",
    "print(ex_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "with open('companys.txt', 'r') as f:\n",
    "    for lines in f:\n",
    "        company_name.append(lines.split('\\n')[0])\n",
    "#print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(company_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取第二种格式的涨跌幅度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.randint(len(news), size = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con = []\n",
    "for i in sample:\n",
    "    match = pattern4.findall(news[i])\n",
    "    con.append(match)\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con[0][0].encode('utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去掉第一种涨跌幅度里的（）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change = []\n",
    "for i in sample:\n",
    "    ordi = []\n",
    "    for ele in ex_rate[i]:\n",
    "        ele1=re.sub(r'\\(','',ele)\n",
    "        ele2=re.sub(r'\\)','',ele1)\n",
    "        ordi.append(ele2)\n",
    "    change.append(ordi)\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_data = []\n",
    "for i in sample:\n",
    "    sample_data.append(seg_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到news对应的公司名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news_entity = []\n",
    "for sentence in sample_data:\n",
    "    entity = []\n",
    "    for word in sentence:\n",
    "        #print(word)\n",
    "        if word.encode('utf8') in company_name:\n",
    "            entity.append(word)\n",
    "    news_entity.append(entity)\n",
    "print(news_entity)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_entity[0][0].encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verb_entity = []\n",
    "#for sentence in sample_data:\n",
    "#    entity = []\n",
    "#    for word in sentence:\n",
    "#        for verb in verb_list:\n",
    "#            if word == verb:\n",
    "#                entity.append(word.encode('utf8'))\n",
    "#    verb_entity.append(entity)\n",
    "#print(verb_entity)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据填入模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact = []\n",
    "func = lambda x,y:x if y in x else x + [y]\n",
    "for i in np.arange(len(sample_data)):\n",
    "    entity = reduce(func, [[], ] + news_entity[i])\n",
    "    if (len(entity) == 0): continue\n",
    "    elif (len(entity) == 1):\n",
    "        if (len(change[i]) != 0):\n",
    "            fact.append(entity[0].encode('utf8') + '增长' + change[i][0].encode('utf8') + \"，\") \n",
    "        elif (len(con[i]) != 0):\n",
    "            string = entity[0].encode('utf8')\n",
    "            for ele in con[i]:\n",
    "                string = string + ele.encode('utf8') + \"，\"\n",
    "            fact.append(string)\n",
    "    else:\n",
    "        j = 0\n",
    "        string = ''\n",
    "        try:\n",
    "            if (len(change[i]) != 0):\n",
    "                for ele in entity:\n",
    "                    string = string + ele.encode('utf8') + '增长' + change[i][j].encode('utf8') + \"，\"\n",
    "                    j += 1\n",
    "            else:\n",
    "                wad = []\n",
    "                for co in con[i]:\n",
    "                    match = pattern5.findall(co)\n",
    "                    if(len(match) != 0):\n",
    "                        wad.append(match)\n",
    "                if (len(wad) == 0):\n",
    "                    for ele in entity:\n",
    "                        string = string + ele.encode('utf8') + con[i][j].encode('utf8') + \"，\"\n",
    "                        j += 1\n",
    "                else:\n",
    "                    for ele in entity:\n",
    "                        string = string + ele.encode('utf8') + wad[j].encode('utf8') + \"，\"\n",
    "                        j += 1\n",
    "                fact.append(string) \n",
    "        except:\n",
    "            ;\n",
    "print(fact)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fact[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据句子生成文章 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\n",
    "for ele in fact:\n",
    "    article = article + ele\n",
    "with open(\"article.txt\", \"w\") as l:\n",
    "    l.write(article)\n",
    "#l.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
